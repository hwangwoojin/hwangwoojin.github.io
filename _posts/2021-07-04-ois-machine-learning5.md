---
layout: post
title: (오일석 기계학습 정리 5) 심층학습 최적화
date:   2021-07-04 19:00:00 +0900
description: 심층학습 최적화에 대해 알아보자.
categories: 프로그래머스-인공지능-데브코스
---

기계 학습에서 최적화가 잘 되었다는 것에 의미는 훈련집합으로 학습을 마친 후 새로운 샘플에 대해 잘 예측하는 것을 말합니다. 즉 일반화(Generalization) 성능이 좋다면 최적화가 잘 되었다고 말할 수 있습니다.

그러나 기계 학습에서 최적화는 다음과 같은 어려움이 존재합니다. 훈련집합과 실제 데이터의 이질성이 존재합니다. 또 고차원 특징공간에 데이터는 희소하게 존재합니다. 마지막으로, 학습에 긴 훈련시간을 가집니다. 따라서 최적화를 위해서는 여러 요소를 고려해야 합니다.

## 목적함수

**목적 함수**는 훈련 집합을 학습할 때 그 성능을 측정하여 매개변수 가중치를 적절한 방향으로 개선할 수 있도록 하는 함수입니다.

신경망에서는 일반적으로 **평균제곱오차(MSE, Mean squared error)**를 사용했습니다.

$$e=\frac{1}{2}\vert\vert y-o\vert\vert^2_2$$

MSE는 오차가 클수록 $$e$$값을 크게 만드는 식으로 동작합니다. 이 방법은 간단하지만 한계가 존재하는데, 바로 신경망 학습 과정에서 오차가 더 크더라도 오차 역적파 과정에서 더 적은 경사도로 갱신될 수 있다는 것입니다. 즉 오차가 큰 경우에도 더 낮은 $$e$$를 받는 경우가 있어서 학습이 더디게 일어나게 됩니다.

이 문제를 해결하기 위해서 **교차 엔트로피(Cross entropy)**를 사용할 수 있습니다. 교차 엔트로피란 두 확률 분포를 통해서 오차를 표현하는 방법입니다.

$$e=-\sum_{i=1,c}(y_ilog_2o_i+(1-y_i)log_2(1-o_i))$$

이를 사용하면 오차가 더 큰 경우 더 큰 경사도를 부과하여 MSE에서의 느린 학습문제를 해결할 수 있습니다.

**음의 로그우도(NLL, Negative log-likelihood)** 목적함수는 MSE나 교차 엔트로피와 다르게 정답에 해당하는 노드만 적용하는 방법입니다.

$$e=-log_2o_y$$

음의 로그우도는 신경망에서 정답에 해당하는 노드만 관찰하겠다는 것을 말합니다. 이 때 정답에 해당하는 값의 확률분포를 표현하기 위해 소프트맥스 함수를 사용합니다.

**소프트맥스(Softmax)** 함수는 부드러운 최대 함수를 말합니다. 출력이 가장 큰 것을 1에 가까운 값을 주고, 나머지를 총합이 1이 되도록 조정하는 함수입니다. 최댓값을 더욱 더 활성화하는 특징이 있습니다.

$$o_j=\frac{e^{sj}}{\sum_{i=1,c}e^{si}}$$

로지스틱 시그모이드의 경우, 각 부류의 확률이므로 총합이 1이 아니고 확률 분포도 아니게 됩니다. 따라서 이를 소프트맥스 함수를 통해 확률분포로 만들 수 있습니다.

음의 로그우도와 소프트맥스 함수는 자주 결합하여 사용됩니다.

## 데이터 전처리

**규모(scale) 문제**란, 데이터의 규모가 차이가 나서 발생하는 문제를 말합니다. 이 경우 특징값의 차이가 크더라도 규모가 작아서 느리게 학습되는 경우가 존재합니다.

예를 들어 몸무게 75kg과 45kg은 30의 차이를 가지지만, 키 1.8m와 1.5m는 0.3의 특징값 차이를 가져서 약 100배정도 느리게 학습되게 됩니다.

**모든 특징이 양수인 경우** 가중치가 뭉치로 증가 또는 감소하는 현상이 발생합니다. 즉 가중치가 항상 증가하는 노드가 존재하고 가중치가 항상 감소하는 노드가 존재합니다. 이 경우 최적점을 탐색할 때 갈팡질팡하여 느린 수렴을 보일 수도 있습니다.

이 문제는 **정규화(normalization)**를 통해 해결할 수 있습니다. 정규분포를 사용하면 모든 데이터를 평균이 0이고 표준편차가 1인 분포로 변환할 수 있습니다.

$$x_i^{new}=\frac{x_i^{old}-\mu_i}{\sigma_i}$$

이 외에도 최대최소변환을 적용할 수도 있습니다. 이 경우 규모의 문제는 해결하지만 양수 문제를 해결해주지는 않습니다.

$$x_i^{new}=\frac{x_i^{old}-min(x_i)}{max(x_i)-min(x_i)}$$

데이터가 남자, 여자와 같이 명목 변수(norminal value)로 주어진 경우, 이를 **원핫(one-hot)** 코드로 변환할 수 있습니다. 이는 남자를 [1,0], 여자를 [0,1]와 같이 변환하는 방법입니다.

원핫코드는 데이터의 종류가 많아질 수록 크기가 커지는 문제가 있습니다.

## 가중치 초기화

같은 가중치를 가지는 노드가 존재하는 경우, 두 노드가 같은 역할을 하는 중복이 발생합니다. 이 경우 노드의 가중치를 난수로 초기화하여 대칭을 파괴할 수 있습니다.

난수의 경우, 주로 가우시안 분포로부터 생성합니다. 난수 범위는 노드로 들어오는 가중치가 $$n_{in}$$개일 때, 주로 다음 범위에서 사용합니다.

$$[-\frac{1}{\sqrt{n_{in}}}, \frac{1}{\sqrt{n_{in}}}]$$

그 예로 ResNet에서는 평균 0, 표준편차 $$\sqrt{\frac{2}{n_{in}}}$$인 가우시안에서 난수를 생성하여 사용했습니다.

## 모멘텀

기계 학습에서는 훈련 집합을 사용하여 경사도를 추정하므로 잡음 가능성이 높습니다. **모멘텀(momentum)**이란 경사도를 부드럽게 추정하여 잡음 효과를 줄이는 방법을 말합니다. 즉 이전에 이동했던 관성을 유지하여 잡음을 줄이게 됩니다.

$$\theta = \theta - \alpha v-p\frac{\partial J}{\partial \theta}$$

$$v$$는 이전 경사도를 누적한 값이고, $$\alpha$$는 관성의 정도를 말합니다. $$\alpha$$가 0이면 관성을 적용하지 않으며 1에 가까울수록 이전 경사도 정보에 큰 가중치를 주게 됩니다. 주로 0.5, 0.9, 0.99를 사용합니다.

모멘텀은 지역 최적점이나 경사도가 없는 점에 빠지는 문제를 해소하여 수렴을 빠르게 하는 장점이 있습니다.

**네스테로프(Nesterov)** 가속 경사도는 현재 $$v$$값으로 다음 이동할 곳을 예측하여, 예측한 곳의 $${\partial J}{\partial \theta}$$를 사용하는 방식입니다.

$$\hat\theta = \theta - \alpha v$$

$$\theta = \theta - \alpha v + p\frac{\partial J}{\partial \theta}\big\vert_{\hat\theta}$$

네스테로프 가속 경사도는 수렴을 더 빠르게 하는 장점이 있습니다.

## 적응적 학습률

학습률 $$p$$는 너무 크면 학습이 갈팡질팡하는 현상이 나타나고, 너무 작으면 수렴이 느린 현상이 나타납니다. 따라서 적절한 학습률을 정하는 것이 중요합니다.

기존의 가중치 갱신은 모든 매개변수에 같은 크기의 학습률 $$p$$를 사용하였습니다. **적응적 학습률(Adaptive learning rate)**란 매개변수마다 자신의 상황에 따라 학습률 $$p$$을 조절해서 사용하는 전략을 말합니다.

**AdaGrad(Adaptive gradient)**는 과거의 그레디언트 정보를 저장해서 이후 그레디언트를 구할 때 사용하는 대표적인 방법입니다.

```python
난수를 생성하여 초기해 a를 설정한다.
r = 0
repeat:
    그레디언트 g를 구한다.
    r = r + g*g # (*는 요소별 곱)
    da = -(p / eps / sqrt(r)) *g # (*는 요소별 곱)
    a = a + da
until(멈춤 조건)
최적의 매개변수 a = a
```

이 때 $$\frac{p}{eps * \sqrt{r}}$$`는 상황에 따라 보폭을 정해주는 적응적 학습률이 됩니다.

AdaGrad는 경사도의 제곱을 더하므로 오래된 경사도와 최근 경사도가 같은 비중이 되는 문제가 존재합니다. **RMSProp**은 가중 이동 평균(weight moving average) 기법을 적용해서 최근 것에 좀 더 비중을 두는 방법입니다.

```python
난수를 생성하여 초기해 a를 설정한다.
r = 0
repeat:
    그레디언트 g를 구한다.
    r = mr + (1-m)g*g # (*는 요소별 곱)
    da = -(p / eps / sqrt(r)) *g # (*는 요소별 곱)
    a = a + da
until(멈춤 조건)
최적의 매개변수 a = a
```

이 때 m이 작을 수록 최근 것에 비중을 더 두게 됩니다. m으로는 보통 0.9, 0.99, 0.999를 사용합니다.

**Adam(Adaptive momentum)**은 RMSProp에 모멘텀을 추가로 적용한 방법입니다.

```python
난수를 생성하여 초기해 a를 설정한다.
r = 0
v = 0
t = 1
repeat:
    그레디언트 g를 구한다.
    v = nv - (1-n)g # 속도 벡터
    v = v / (1 - n^t)
    r = mr + (1-m)g*g # 그레디언트 벡터
    r = r / (1 - m^t)
    da = -(p / eps / sqrt(r)) *v # (*는 요소별 곱)
    a = a + da
until(멈춤 조건)
최적의 매개변수 a = a
```

이 때 n은 주로 0.9, 0.999, 1e-3, 5e-4로 설정합니다.

## 활성 함수

활성함수란 활성값을 변환시켜주는 비선형 함수를 말합니다. 즉 활성값 또는 결과값 $$z$$에 대해 출력을 매핑하는 함수입니다.

$$x = w^Tx + b$$

$$y = \tau(z)$$

초기에 활성함수는 선형함수, 계단함수를 사용하다가 이후에 tanh, 시그모이드 함수를 사용하였습니다. 그러나 시그모이드 함수의 경우, 활성값이 커지면 포화상태가 되어 그레디언트 손실 문제가 발생합니다.

이를 극복하기 위해 ReLU 함수가 등장하였습니다. ReLU 함수는 그레디언트 손실 문제를 방지하는 특징이 있습니다.

$$y = ReLU(z) = max(0, z)$$

단, ReLU 또한 0 이하의 모든 값에 대해서 0인 문제가 존재합니다. 이를 위해서 LeakyReLU 등 여러 활성함수가 등장하였습니다.

## 배치 정규화

공변량 시프트(Covariate shift)란 학습을 수행할 때 데이터의 분포가 계속 달라지는 문제를 말합니다. 이 경우 그레디언트가 폭발하거나 손실하는 등 학습이 제대로 되지 않게 됩니다.

**배치 정규화(Batch normalization)**는 공변량 시프트 현상을 누그러뜨리기 위해 층마다 정규화를 적용하는 방법을 말합니다. 주로 CNN층, FC층에서 활성함수에 통과하기 직전에 사용합니다. 또 미니배치에 적용하는 것이 유리합니다.

$$x_i^{new} = \frac{x_i^{old}-\mu_i}{\sigma_i}$$

배치 정규화는 신경망의 그레디언트 흐름을 개선하고, 높은 학습률을 허용하며, 초기화에 대한 의존성을 감소시키는 장점이 있습니다.

## 규제

기계 학습 문제를 풀 때, 모델 용량이 지나치게 커서 발생하는 과대적합(over-fitting) 문제와, 모델 용량이 지나치게 작아서 발생하는 과소적합(under-fitting) 문제가 발생할 수 있습니다. 그래서 보통은 용량이 큰 모델과 규제를 통해 해결하는 방법을 사용합니다.

**규제(Regularization)**란 모델 용량에 비해 데이터가 부족한 경우를 해결하기 위한 방법입니다. 이를 위해서는 적절한 가정을 사용하게 되는데, 입력과 출력 사이의 변환이 매끄럽다는 **매끄러움 가정**이 대표적입니다.

$$J_{reg}(\theta;X,Y)=J(\theta;X,Y)+\lambda R(\theta)$$

규제항은 매개변수를 작은값으로 유지해서 모델의 용량을 제한하는 역할을 수행합니다. 이는 가중치를 줄이는 방법이기 때문에, **가중치 감쇠(weight decay)**라고도 합니다.여기서 규제항은 훈련집합과 무관한 사전 지식에 해당합니다. 규제항으로는 L1 놈과 L2놈을 주로 사용합니다.

**L2 놈(Norm)**은 다음과 같습니다.

$$J_{reg} = J + \lambda\vert\vert\theta\vert\vert_2^2$$

이를 미분하고 $$\theta$$에 대해 정리하면 다음과 같습니다.

$$\theta=(1-2p\lambda)\theta-p\triangledown J$$

이는 $$\theta$$에 $$(1-2p\lambda)$$만큼 곱해주는 셈입니다. 이는 결국 해를 원점 가까이 당기는 효과를 주게 되며 가중치를 작게 유지할 수 있도록 합니다.

**L1 놈**은 다음과 같습니다.

$$J_{reg}=J+\lambda\vert\vert\theta\vert\vert_1$$

이를 미분하고, $$\theta$$에 대해 정리하면 다음과 같습니다. 이 때 $$sign$$은 부호를 나탄냅니다.

$$\theta = \theta - p\triangledown J-p\lambda sign(\theta)$$

이는 $$p\lambda sign(\theta)$$ 만큼 추가로 $$\theta$$를 이동시키는 방법입니다. 이는 결론적으로 매개변수를 0으로 만들어 희소하게 만드는 효과가 있으며, 선형 회귀에는 특징 선택이라는 효과가 있습니다.

## 조기 멈춤

조기 멈춤이란 성능 향상이 없더라도 어느정도는 기다리도록 하여 이른 수렴 현상을 막는 방법입니다.

## 데이터 확대

**데이터 확대(Data augmentation)**이란 데이터를 인위적으로 변형하여 확대함으로써 훈련집합의 크기를 크게 하여 과잉적합을 방지하는 방법입니다.

## 드롭아웃

**드롭아웃(Dropout)**이란 FC층의 노드 중 일정 비율을 제거하여 남은 부분의 신경망만 학습하여 과적합을 방지하는 방법입니다. 

## 앙상블

**앙상블(Ensemble)**은 여러 다른 모델을 결합하여 일반화 오류를 줄인는 기법입니다.

## 하이퍼 파라미터 최적화

보통 매개변수라고 하면 모델 내부의 가중치를 말합니다. **하이퍼 파라미터**란 모델 외부에서 학습을 결정하는 매개변수들을 말하며, 이 값들은 주로 사람에 의해 결정됩니다. 하이퍼 파라미터는 그리드 탐색, 랜덤 탐색 등 다양한 탐색 방법을 통해 찾게 됩니다.
