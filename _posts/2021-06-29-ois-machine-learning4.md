---
layout: post
title: (오일석 기계학습 정리 4) 심층학습 기초
date:   2021-06-29 09:00:00 +0900
description: 심층학습의 기초에 대해 알아보자
categories: 프로그래머스-인공지능-데브코스
---

**심층학습(Deep learning)**이란 다층 퍼셉트론에 은닉층을 여러개 추가하여 신경망을 깊게 만든것을 말합니다. 심층학습은 기존에 풀지못했던 여러 한계들을 해결하였습니다. ReLU 활성함수를 사용하여 그레디언트 소멸(Gradient vanishing) 문제를 극복하였고, 다양한 규제 기법을 적용하여 과잉적합을 방지합니다.

심층학습의 여러 은닉층은 특징 추출기를 의미합니다. 얕은 신경망에서는 사람이 직접 특징을 가공하여 제한적으로 특징을 추출하는 것과는 다르게, 심층학습은 자동적으로 데이터로부터 특징을 추출하는 표현 학습(Representation learning)적인 특성을 가집니다.

이 때 낮은 단계 은닉층은 선이나 모서리와 같은 간단한 특징을 추출하고, 높은 단계 은닉층은 눈, 입 등 추상적이고 복잡한 특징을 추출합니다.

이는 퍼셉트론을 여러개로 쌓은 형태이기 때문에 깊은 다층 퍼셉트론(DMLP)이라고 부르기도 합니다. 이는 다층 퍼셉트론을 확장한 형태입니다.

## 컨볼루션 신경망

**컨볼루션(합성곱) 신경망(Convolutional neural network)**란 컨볼루션층과 풀링층으로 구성된 신경망을 말합니다. 컨볼루션(Convolution)층은 선형함수인 컨볼루션과 비선형 함수인 활성함수로 구성된 층이고, 풀링(Pooling)층은 컨볼루션의 얻어진 특징을 요약하고 강화하는 층입니다.

영상은 동일한 객체라도 영상을 찍는 카메라 위치나 조명에 따라 픽셀값이 바뀌게 됩니다. 또 경계색때문에 배경과 물체가 구분이 되지 않을 수도 있습니다. 영상 분야에서 특징을 추출하기 위해서 컨볼루션 신경망이 주로 사용됩니다.

DMLP는 모든 신경망이 완전 연결(fc) 구조라 복잡도가 높고 과잉적합이 일어날 수 있습니다. 그러나 CNN은 부분 연결을 통해 복잡도를 낮추고 과잉적합을 방지합니다. 이것이 가능한 이유는 주어진 데이터가 이미지이기 때문입니다. 이미지는 인접한 픽셀이 연관성이 큰 특징을 가지고 있습니다.

CNN은 필터(커널)라고 불리는 것을 사용하여 특징맵을 출력합니다. 모든 노드에서 동일한 필터를 사용하므로 학습 파라미터를 크게 줄일 수 있습니다. 또 공간정보를 유지하므로 인접한 정보의 특징을 효과적으로 인식하게 됩니다. 만약 필터 값이 다르면 추출하는 특징도 달라지게 됩니다. 필터는 오류 역전파를 통해 스스로 학습하게 됩니다.

외곽 정보의 경우 커널을 통해 곱할 때, 패딩(padding)을 통해 의미없는 값을 넣거나, 인접갑을 넣어서 처리하기도 합니다. 퍼셉트론처럼 편향(bias)값을 추가할 수도 있습니다. 필터를 이동시킬 때 보폭을 1보다 크게 하는 경우 다운샘플링(Down sampling)을 적용할 수 있습니다.
